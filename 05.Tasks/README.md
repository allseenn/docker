# Контейнеризация

Урок 5. Docker Compose и Docker Swarm

## Задания

### Задание 1

1. создать docker compose файл, состоящий из 2 различных контейнеров: 1 - веб, 2 - БД
2. запустить docker compose файл
3. по итогу на БД контейнере должно быть 2 реплики, на *adminer* должна быть 1 реплика. Всего должно получиться 3 контейнера
4. выводы зафиксировать

### Задание 2*

1. создать кластер и мастер и слейв ноды
2. задеплоить на ноду несколько экземляров какого0нибудь контейнера, например nginx
3. обязательно проверить и зафиксировать результаты, чтобы можно было выслать преподавателю для проверки

<div style="page-break-after: always;"></div>

## Решение

### Задание 1 (docker-compose.yaml)

Создадим папку проекта *adminer* и в ней *docker-compose.yaml*

```
vim docker-compose.yaml
```

<img src=pics/11.png>

Внутри файла указываем инструкции в разделе *services* две службы: *adminer*, *mariadb*

В свою очередь каждая служба будет содержать другие инструкции:

- **image** - образ и версия службы (системы)
- **container_name** - имя, которое будет присвоено контейнеру
- **ports** - пробрасываемые порты с контейнера на хостовую систему
- **environment** - переменные окружения контейнера
- **deploy** опции развертывания такие, как *mode* и *replicas*
- **replicas** - количество реплик (контейнеров) для данной службы

Когда файл готов, запускаем, в папке проекта *adminer*, команду

```
docker compose up
```

Загрузятся необходимые образы и произойдет разворачивание служб в соответствии с инструкциями

<img src=pics/12.png>

Весь процесс установки и развертывания с возможными ошибками выводится в терминал

<img src=pics/13.png>

После успешного поднятия служб в соответствии с *docker-compose.yaml*, можно зайти в *adminer* и управлять *mariadb*

<img src=pics/14.png>

Т.к. команда выполнялась без запуска в режиме демона, то вся служебная информации выводится в терминал, в частности мы можем наблюдать в режиме реального времени обращения к *adminer* через веб-сервер

<img src=pics/15.png>

### Задание 2 (docker swarm)

Развернем кластерную систему на трех реальных системах

- **FEN** - ubuntu 22.04 (основной сервер)
- **XU2210** - ubuntu 22.10
- **XU2004** - ubuntu 20.04

Создадим на основном сервере **FEN** папку проекта *claster* и поместим в нее *docker-compose.yaml* и *nginx.conf* для дальнейшего развертывания.

<img src=pics/21.png>

Синтаксис, одинаковый, т.к. исполняется тем же **docker compose**, только присутствуют специфичные инструкции в директиве *deploy*:
*placement* и *constraints*, которые указывают роль конкретного узла в кластере: *manager* или *worker*

<img src=pics/22.png>

Файл *nginx.conf* тоже будет иметь специфические настройки для распределения нагрузки между веб-серверами и переадресацией запросов в случае недоступности узлов.

Инициализация кластерной системы докера производится командой

```
docker swarm init
```

При наличии нескольких сетевых интерфейсов, либо адресов можно указать конкретный с ключом *--advertise-addr*.
После успешной инициализации появится команда для присоединения других машин к нашему кластеру

<img src=pics/23.png>

Используем команду присоединения на **XU2210**

<img src=pics/24.png>

Используем команду присоединения на **XU2004**

<img src=pics/25.png>

Вывод информации об узлах выполняется командой

```
docker node ls
```

На выводе видим список узлов, кто является менеджером, кто рабочим их статусы и готовность

<img src=pics/26.png>

На наших трех узлах разворачиваем (деплоим) веб-сервера *nginx* командой

```
docker stack deploy -c docker-compose.yaml gbnginx
```

В результате поднимается служебная сеть *gbnginx_mynetwork*
По одному контейнеру с веб-сервером на каждый узел, кроме мастера, на котором так же разворачивается балансировщик нагрузки

<img src=pics/27.png>

Более детальную информацию по каждой запущенной службе и узле размещения можно посмотреть командой

```
docker service ps gbnginx_nginx-master
```

В частности отобразится информация о ноде *fen* размещенной на основном сервере **FEN**:

- Id
- имя узла
- имя образа
- узел
- желаемое состояние
- текущее состояние
- ошибки
- порты

Обращение браузером к узлу XU2004

<img src=pics/28.png>

<div style="page-break-after: always;"></div>

Обращение браузером к узлу XU2210

<img src=pics/29.png>

Обращение браузером к узлу FEN

<img src=pics/30.png>

Статусы узлов можно повысить командой

```
docker node promote XU2004

```
Так статус менеджера можно присвоить сразу всем узлам

<img src=pics/31.png>

### Заключение

Данная связка работает хорошо, в случае отключения сразу двух любых узлов, третий берет на себя всю нагрузку.
Но, в случае если умирает главный сервер, в моем случае FEN, остальные работают хорошо до их (worker) перезагрузки.
Т.е. существует гипотетическая вероятность глобального блэкаута, при котором, старт не основного узла не возобновит работу веб-службы, до тех пор пока не стартует инициализирующая всех нода, даже если всем узлам присвоить статус менеджера.

Как вариант, нужно делать инициализацию кластера сразу на трех серверах и организовывать перекрестные контейнеры на каждом узле, но представляется сложным решением, в плане организации, обслуживания и дальнейшего масштабирования.

На данный момент, знаю решение вопроса блэкаута только без организации кластера, с помощью модуля nginx, а именно
[http_health_check](https://docs.nginx.com/nginx/admin-guide/load-balancer/http-health-check). С помощью него можно организовать независимые веб-сервера, но необходимо с помощью unison, либо rsync настроить синхронизацию контента, есть встроенные способы кластеризации и у mariadb (mysql). Но, это все требует больших временных трудозатрат.

Возможно есть более легкие решения на случай блэкаута, для docker swarm.
